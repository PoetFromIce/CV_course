{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Лабораторная работа №1:\n",
        "SDXL – гибридная модель для для генерации изображений"
      ],
      "metadata": {
        "id": "H0sZAbsGbkro"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MN7oO7oMDmX6"
      },
      "outputs": [],
      "source": [
        "# --- A) INSTALL ---------------------------------------------------------------\n",
        "!pip -q install --upgrade diffusers transformers accelerate safetensors \\\n",
        "                controlnet_aux peft datasets sentencepiece hf_xet \\\n",
        "                fsspec==2025.3.2 gcsfs==2025.3.2 --progress-bar off\n",
        "\n",
        "from huggingface_hub import login\n",
        "login(\"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\")   # ← ваш токен HF\n",
        "\n",
        "print(\"✅ Библиотеки установлены. Перезапустите runtime: Runtime → Restart.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Инициализируем пайплайн SDXL-Turbo и генерируем тестовое изображение с помощью DDIM-шедулера"
      ],
      "metadata": {
        "id": "nVzkEG_R0w_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# 2) Imports & helpers\n",
        "# =============================================================================\n",
        "import torch, gc, cv2, numpy as np\n",
        "from PIL import Image\n",
        "from IPython.display import Image, display\n",
        "from diffusers import (\n",
        "    DiffusionPipeline, StableDiffusionXLControlNetPipeline,\n",
        "    ControlNetModel, DDIMScheduler, AutoencoderKL\n",
        ")\n",
        "from huggingface_hub import login\n",
        "login(\"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\")\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def free():\n",
        "    torch.cuda.empty_cache(); gc.collect()\n",
        "\n",
        "# =============================================================================\n",
        "# 3) Text‑to‑Image · SDXL‑Turbo + DDIM (50 steps, 768²)\n",
        "# =============================================================================\n",
        "prompt = \"a photograph of a snowy mountain landscape at sunrise\"\n",
        "neg    = \"blurry, low resolution, bad quality\"\n",
        "\n",
        "pipe_turbo = DiffusionPipeline.from_pretrained(\n",
        "    \"stabilityai/sdxl-turbo\",\n",
        "    torch_dtype=torch.float16,\n",
        "    variant=\"fp16\",\n",
        "    device_map=\"balanced\",\n",
        "    low_cpu_mem_usage=True\n",
        ")\n",
        "pipe_turbo.enable_attention_slicing()\n",
        "pipe_turbo.scheduler = DDIMScheduler.from_config(pipe_turbo.scheduler.config)\n",
        "\n",
        "img = pipe_turbo(prompt, negative_prompt=neg,\n",
        "                 height=768, width=768,\n",
        "                 num_inference_steps=50, guidance_scale=0.0).images[0]\n",
        "img.save(\"01_turbo_ddim.png\"); img.show()\n",
        "\n",
        "del pipe_turbo; free()\n",
        "\n",
        "# =============================================================================\n",
        "# 4) ControlNet (Canny) over SDXL‑Base 1.0\n",
        "# =============================================================================\n",
        "# 4-a) ControlNet on CPU (exactly как было)\n",
        "ctrl = ControlNetModel.from_pretrained(\n",
        "    \"diffusers/controlnet-canny-sdxl-1.0\",\n",
        "    torch_dtype=torch.float16, variant=\"fp16\"\n",
        ")                          # ← остаётся на CPU\n",
        "\n",
        "# 4-b) SDXL-Base 1.0 on CPU\n",
        "\n",
        "vae = AutoencoderKL.from_pretrained(\"madebyollin/sdxl-vae-fp16-fix\", torch_dtype=torch.float16)\n",
        "pipe_cn = StableDiffusionXLControlNetPipeline.from_pretrained(\n",
        "    \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
        "    controlnet=ctrl, vae=vae,\n",
        "    torch_dtype=torch.float16, variant=\"fp16\"\n",
        ")                          # всё ещё на CPU\n",
        "pipe_cn.enable_model_cpu_offload()"
      ],
      "metadata": {
        "id": "pzDXVSjrHx6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подготавливаем ControlNet-Canny поверх SDXL-Base (B–C), загружая модель контуров на CPU и используя CPU-offload-хуки, чтобы слои мигрировали на GPU и обратно. Получаем результат по Canny-контурной карте."
      ],
      "metadata": {
        "id": "gmYqa_s11CeB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- C-finish : запуск ControlNet --------------------------------------------\n",
        "import cv2, numpy as np\n",
        "from PIL import Image\n",
        "base = Image.open(\"01_turbo_ddim.png\").convert(\"RGB\").resize((640, 640))\n",
        "edge = Image.fromarray(cv2.Canny(np.array(base), 100, 200))\n",
        "\n",
        "res = pipe_cn(prompt, image=edge, negative_prompt=neg,\n",
        "              height=640, width=640,\n",
        "              num_inference_steps=100, guidance_scale=6.0).images[0]\n",
        "res.save(\"02_controlnet_canny.png\"); res.show()\n",
        "\n",
        "del pipe_cn, ctrl; free()\n",
        "print(\"✅ 02_controlnet_canny.png готово — сделайте Runtime → Restart.\")"
      ],
      "metadata": {
        "id": "bIFTwce6Fx8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "после перезапустить среду выполнения"
      ],
      "metadata": {
        "id": "eECjHXFO7y9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install \"datasets==2.14.6\" --no-deps --progress-bar off"
      ],
      "metadata": {
        "id": "LrxY35iCdr2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install multiprocess xxhash tqdm pyarrow --progress-bar off"
      ],
      "metadata": {
        "id": "ar3FC9iJd89V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install --upgrade \\\n",
        "    diffusers transformers accelerate safetensors controlnet_aux \\\n",
        "    peft datasets sentencepiece xformers"
      ],
      "metadata": {
        "id": "Wb5xsx5b8NBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login(\"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\")  # ваш токен\n",
        "print(\"✅ Установлено — теперь Runtime → Restart runtime\")"
      ],
      "metadata": {
        "id": "NJbBPSKT8VM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "после перезапустить сеанс"
      ],
      "metadata": {
        "id": "vJdDYeDh8Z-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import os\n",
        "ds = load_dataset(\"Dasool/VERI-Emergency\", split=\"train[:200]\")\n",
        "os.makedirs(\"pokemon_images\", exist_ok=True)\n",
        "for i, ex in enumerate(ds):\n",
        "    ex[\"image\"].convert(\"RGB\").save(f\"pokemon_images/{i:04d}.jpg\")\n",
        "    with open(f\"pokemon_images/{i:04d}.txt\", \"w\") as f:\n",
        "        f.write(ex[\"caption\"])\n",
        "print(\"✅ Скачано 200 изображений в папку pokemon_images/\")\n"
      ],
      "metadata": {
        "id": "EH89v5p0kUTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/huggingface/diffusers.git"
      ],
      "metadata": {
        "id": "1oxEL5zNsTOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Удаляем старую версию diffusers\n",
        "!pip uninstall -y diffusers\n",
        "\n",
        "# 2. Устанавливаем PyTorch (если ещё не установлен), Accelerate и Transformers\n",
        "!pip install torch accelerate transformers\n",
        "# перезапускаем сеанс"
      ],
      "metadata": {
        "id": "FV6mfHNKsyS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LoRa fine-tuning\n",
        "LoRA нацелен на решение проблемы тонкой настройки LLM. Она представляет обновление весов двумя меньшими матрицами обновления с помощью низкоранговой декомпозиции, со значительно меньшим количеством параметров. Она замораживает веса модели замораживаются на протяжение всего процесса, позволяя обучить новые матрицы, после чего адаптированные веса объединяются с исходными весами.Затем эти матрицы могут быть обучены для адаптации новых данных.\n",
        "Это занимает куда меньше времени чем полноценна настройка модели и допускает комбинацию с другими техниками"
      ],
      "metadata": {
        "id": "rCc_CG508fBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Устанавливаем последнюю версию библиотеки прямо из GitHub\n",
        "!pip install --upgrade git+https://github.com/huggingface/diffusers.git"
      ],
      "metadata": {
        "id": "cOeD-UMU8fVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Скачивание и сохранение датасета с покемонами для последующего fine-tuning.\n",
        "!mkdir pokemon_images_jpg\n",
        "!mv pokemon_images/*.jpg pokemon_images_jpg/"
      ],
      "metadata": {
        "id": "tYlUkbq_8kcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!!pip install --upgrade bitsandbytes"
      ],
      "metadata": {
        "id": "4fR4fpC58nXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проводим fine-tuning LoRA-адаптера с рангом 4 на SDXL (DreamBooth-скрипт из примеров diffusers), используя градиентный чекпоинтинг, смешанную точность и memory-efficient attention."
      ],
      "metadata": {
        "id": "VGyQdNEL8n2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/facebookresearch/bitsandbytes.git\n",
        "!pip install ./bitsandbytes\n",
        "# перезапускаем сеанс"
      ],
      "metadata": {
        "id": "GoVDJNh68oj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "перезапускаем сеанс"
      ],
      "metadata": {
        "id": "Gt1ENi_u8tWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python diffusers/examples/advanced_diffusion_training/train_dreambooth_lora_sdxl_advanced.py \\\n",
        "  --pretrained_model_name_or_path stabilityai/stable-diffusion-xl-base-1.0 \\\n",
        "  --instance_data_dir ./pokemon_images_jpg \\\n",
        "  --instance_prompt \"fire in the house\" \\\n",
        "  --output_dir ./pokemon_lora \\\n",
        "  --resolution 128 \\\n",
        "  --train_batch_size 1 \\\n",
        "  --max_train_steps 5 \\\n",
        "  --learning_rate 1e-4 \\\n",
        "  --gradient_checkpointing \\\n",
        "  --mixed_precision fp16 \\\n",
        "  --enable_xformers_memory_efficient_attention \\\n",
        "  --validation_epochs 1 \\\n",
        "  --num_validation_images 0"
      ],
      "metadata": {
        "id": "ISg_xesmqja4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Применяем дообученный адаптер к SDXL-Base (E), включаем оптимизации (attention- и VAE-slicing) и генерируем финальное изображение с guidance scale ≈ 7.5"
      ],
      "metadata": {
        "id": "OfC7OrKb0nXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ───── E) INFERENCE: применение LoRA в SDXL-Base ──────────────────────────────\n",
        "import torch\n",
        "from diffusers import StableDiffusionXLPipeline\n",
        "from IPython.display import Image, display\n",
        "from PIL import Image as PILImage\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "from huggingface_hub import login\n",
        "login(\"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\")  # ваш токен\n",
        "# 1) Загружаем оригинальный SDXL-Base (fp16) и переносим на GPU\n",
        "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
        "    \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
        "    torch_dtype=torch.float16,\n",
        "    variant=\"fp16\",\n",
        ").to(device)\n",
        "\n",
        "# 2) Подгружаем дообученные LoRA-веса\n",
        "pipe.unet.load_attn_procs(\"pokemon_lora\")\n",
        "\n",
        "# 3) Включаем оптимизации для инференса\n",
        "pipe.enable_attention_slicing()\n",
        "pipe.enable_vae_slicing()\n",
        "pipe.enable_vae_tiling()\n",
        "\n",
        "# 4) Генерируем изображение\n",
        "prompt = \"engulfing fire realistic 4K\"\n",
        "image = pipe(\n",
        "    prompt,\n",
        "    height=768,                   # можно увеличить до 768, если хватает VRAM\n",
        "    width=768,\n",
        "    num_inference_steps=200,       # больше шагов — выше качество\n",
        "    guidance_scale=7.5            # сила влияния guidance\n",
        ").images[0]\n",
        "\n",
        "# 5) Сохраняем и отображаем результат\n",
        "image.save(\"pokemon_lora_result.png\")\n",
        "image.show()\n",
        "display(Image(filename='/content/pokemon_lora_result.png'))\n",
        "print(\"✅ Результат сохранён как pokemon_lora_result.png\")\n"
      ],
      "metadata": {
        "id": "t3tH7yiqnfgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Изображения, сгенерированные диффузионными моделями, могут использоваться для обучения моделей, например, решающих задачу классификации, если сохранить промпты"
      ],
      "metadata": {
        "id": "3fRMJqPuB3HP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Генерация датасета:"
      ],
      "metadata": {
        "id": "7KAzsAPLyHgz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "from diffusers import StableDiffusionXLPipeline\n",
        "import torch\n",
        "\n",
        "# Сколько изображений для датасета вам надо\n",
        "num_images = 10\n",
        "# Укажите промпты для генерации\n",
        "base_prompts = [\n",
        "    \"кошка\",\n",
        "]\n",
        "\n",
        "# Генерируем список подсказок для 10 изображений\n",
        "prompts = [base_prompts[i % len(base_prompts)] + f\", вариация {i+1}\" for i in range(num_images)]\n",
        "\n",
        "# Папка для сохранения изображений\n",
        "output_dir = \"my_sdxl_dataset\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# CSV-файл для хранения соответствия изображение-подсказка\n",
        "csv_path = os.path.join(output_dir, \"dataset.csv\")\n",
        "\n",
        "# Загрузка пайплайна SDXL\n",
        "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
        "    \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
        "    torch_dtype=torch.float16,\n",
        "    use_safetensors=True\n",
        ").to(\"cuda\")\n",
        "\n",
        "# Генерация и сохранение изображений + запись в CSV\n",
        "with open(csv_path, mode=\"w\", newline='', encoding=\"utf-8\") as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow([\"filename\", \"prompt\"])\n",
        "    for idx, prompt in enumerate(prompts):\n",
        "        image = pipe(prompt, num_inference_steps=30, guidance_scale=7.0).images[0]\n",
        "        filename = f\"image_{idx:03d}.png\"\n",
        "        image.save(os.path.join(output_dir, filename))\n",
        "        writer.writerow([filename, prompt])\n",
        "        print(f\"Сохранено: {filename}\")\n",
        "\n",
        "print(\"Генерация датасета завершена! Все подсказки сохранены в dataset.csv\")\n",
        "display(Image(filename='/content/my_sdxl_dataset/image_000.png'))"
      ],
      "metadata": {
        "id": "-uiSeNBOB3qX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задание:\n",
        "1) Найти датасет или сделать свой, и провести на нем файнтюн модели. Предоставить два изображения, отличающиеся количеством изображений в датасете (32 и 128) чтобы пронаблюдать влияние размера датасета на результат.  \n",
        "2) Пронаблюдать и описать влияние параметров height&width,num_inference_steps, guidance_scale.  \n",
        "3) Сгенерировать свой датасет на опредленную тему и загрузить его на hugging face.  "
      ],
      "metadata": {
        "id": "zHPwqYZDqcro"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9e238bMYqgTf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
